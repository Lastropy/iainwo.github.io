---
layout: single
title: "2019-Week25"
author_profile: true
headline: Week 25 of 2019!
comments: true
---
In this Last Week, in math and in life, I have been locked in contest with problems of constrained optimization.

I did not accomplish my Goal. Period.

> I planned **big** - to crush it. To do (4) Calculus modules in one week. Scheduling myself to complete two of those modules during the week, and then one per each day of the weekend. The results would've been monumental - and despite the size of the challenge, I thought I could accomplish it with composure.

> Even under the duress of having to navigate the events of this week:
> 1. Public Lecture: What is missing from common practice in ML
> 2. ML Workshop: Learning in the presence of class bias
> 3. Ottawa Footy-Sevens Soccer Game
> 4. Get soccer cleats
> 5. Running with a friend

> And the life goals I set out for myself:
> 1. Get to sleep by 9:30 PM
> 2. Plan calendar night before

There is no excuse. I in clear mind set out a Goal last week - and didn't do the necessary things required to achieve it. I could've worked harder, longer hours - staying up past my 9:30 PM bedtime, and leveraged myself in a way where I could have achieved what I set out to do.

## Lessons in Failure
Not all failures are empty; and this week's failure to achieve my main goal came laden with promise for the future.

There are three intimations which I would share with you: (1) creativity, neuroticism and a predilection towards conscientiousness, (2) density of achievement and (3) common adversities of learning. Lessons can be learned from these three ideas.

##### (1) Creativity, Neuroticism and Conscientiousness
Being creative - being anything but normal, while having the same doubts and subject to the same emotions as any other person, is a veritably unstable system. The negative feedback that comes with doing abnormal things will play on your insecurities. It is inevitable and the price you pay for the opportunity to come to conclusions like: "maybe I should switch what I'm doing", "maybe putting my hand in fire was a bad idea", etc. The feedback mechanic is what allows you to make inference, understand interventional and counterfactual ideas. But despite the glorification and utility of that, you still pay the emotional cost and experience torrent of doubts and feelings for excersizing that mechanic. That duress - is not only risky in the short-term - but highly toxic with prolonged exposure. This reminds of remarks made by Dr. Jordan Peterson on [creativity, neuroticism and conscientiousness](https://youtu.be/mQ3fe3vDQao). The central idea of those remarks were - ground thyself - find balance; then leverage that balance as backstop to the disease that comes with trying to be creative or highly productive. Operating under such a framework is one solution for optimal success over time. You can consider this second source by Jordan citing the [dangers of creativity](https://youtu.be/ocDli45faiw).
> Early in last week - around Thursday, I realized I was not on track for meeting my Big Goal. Upon realizing that, I considered the things I could do to combat the adversities I was facing so as to still accomplish what I set out to achieve. I found that it would have meant sacrificing one of my other goals, losing sleep, or possibly burning out. I made the conscious decision to maintain the "stabilizing framework" described in the paragraph above. Keeping the things in my life in order, maintaining disciplined sleep, eating consistently, excersizing consistently, and in general keeping long-term processes in check.

> I do not believe I am at the point which warrants violating this stabilizing structure. I still don't use my day-to-day efficiently enough; and I am also not confident enough that I have even have the ability/skill to consistently maintain this stabilized structure. At the moment, this is why I can't even think about abandoning it.

> The lesson I have derived from this - is stability is a skill. I don't have that skill; and I need to get good at it and leverage it. When I can do that well enough then I can dote on the cost of being too tyrannical.

##### (2) Density of Achievement
In North-America, likely elsewhere too, a vision of success is some business-focused individual like an CEO, an SVP or an Exec which operates with inordinate achievement - in part by setting unbelievable goals and then proving those disbelievers wrong. Unanimously, the individuals who can do this more often than not do very, very well: look at any sports figure - Serena Williams, Floyd Mayweather, Wayne Gretzky, look at any musician: City and Colour, Metallica, Chopin, or any innovator like: Jobs, Steve Jobs, or Steven Jobs ðŸ¤ª they all have done unbelievable things and because of it they are well known. Often lost in my own personal incredulity I forget about an even more important metric than "big wins" - and that metric is consistency or more aptly density of achievement. It is okay to mess up it happens - but more often then not you should be proverbially #charlie-hashtag-winning. A while ago I saw a presentation by Kevin O'Leary on finance; and what enraptured me so, was the emphasis on data-driven economics. One piece of data that Kevin offered was the idea of [consistent achievement](https://www.barrons.com/articles/shark-tanks-kevin-oleary-invests-only-with-women-heres-why-51561159764) over time. The salient remarks of that idea were that - look, if you can hit big - go for the moon, but don't mess up. It is better long-term to be less aggressive and "manage your risk". The converse of which is just have a high density of success.
> My takeaways is I need to first hit a baseline of consistent achievement and success. I can't be setting goals which require cutting corners or up-ending the stabilizing systems in my life - with the risk of not achieving them. There is a place to take risk and there are appropriate times - but look I'm trying to develop my skills here; I need some margin for error and play. I need to be able to iterate quickly, improve quickly, and I can't do that by continually setting risky, chaos inducing, and failure demoralizing outcomes.

> The lesson I have derived from this - is stability first. I want to achieve - and to do so in consistency and with density. I can worry about "crushing it" when I get to that level.

##### (3) Analysis of Adversities in Studying
The last thing to cover is commonalities I've noticed in the lulls of my productivity. Usually these lulls are do to the Academic content which I am learning.

1. I slow down exponentially when I am struggling to understand the mathematical intuition behind various theories. This week Lagrange's multiplier and Constrained Optimization were my bane.
2. The sheer fact of knowing my learning of a lesson or module is protracted is demoralizing and slows me down
3. I underestimated the amount of work - my goal was to finish 4 modules in 1 week for Calculus, the 5th module had sooooooooooo much work. Solving the quizzes for Taylor Series approximations, required pages of partial derivatives.
4. I write notes slowly/learn slowly. A 10 minute video takes me an hour to produce notes on and be comfortable with

> In the future I want to address these difficulties and employ strategies to minimize or entirely mitigate the way they deteriorate my productivity.

## Going Forward

I have these life goals:

1. Continue to get to sleep by 9:30 PM, maybe 9:00 PM
2. Plan calendar night before

I have these ML goals (much more moderate than last week's I know haha):

1. Finish the Coursera: Calculus course by Sunday

You can read up on my mid-term goals [here](https://iainwo.github.io/goals/2019-Week22/).

Some notes I made last week that I am particularly proud of - or thought were cool were:

- The super cool idea of the Lagrangian Multiplier in [L5 CH6 Constrained Optimization](https://iainwo.github.io/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH6%20Constrained%20Optimization.pdf)
- The super cool idea of multivariate approximations with plots [L4 CH10 Multivariate Taylor](https://iainwo.github.io/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH10%20Multivariate%20Taylor.pdf)
- A super pretty note on [L3 CH7 Backpropagation Notebook](https://iainwo.github.io/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH7%20Backpropagation%20Notebook.pdf) **like check this one out for sure**
- A proud moment having learning Jacobians and Hessians in [L3 CH1 Introduction and Multivariate Chain Rule](https://iainwo.github.io/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH1%20Introduction%20and%20Multivariate%20Chain%20Rule.pdf)

A small announcement - in [last week's blog](https://iainwo.github.io/goals/2019-Week24/) I was talking about how I had 7 weeks to achieve my mid-term goals; and then if I were to do that I would feel semi-prepared to join the ML team in August. Well turns out that timeline has been advanced! Next week - July 2nd, I enter my career in Machine Learning and AI. Saludos - software engineering! 

To end off last week - this week, as per Ryan Serhant's advice - "patience and persistence".

See you next week,
- Iain

![Week25-Schedule](https://iainwo.github.io/assets/images/goals/2019Week25_calendar.png)

## Meetups, Courses, and Notes

This week I did these modules:

| No. | Course | Module Name |
| --- | --- | --- |
| 1 | Coursera Mathematics for ML: Multivariate Calculus | Multivariate Chain Rule and it's Application |
| 2 | Coursera Mathematics for ML: Multivariate Calculus | Taylor Series Approximations and Linearisation |

This week I wrote (32) notes (technically 29 by Sunday night),

| No. | Note |
| --- | --- |
| 1.  | [2019-JUN-24 21:32 - L5 CH6 Constrained Optimization.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH6%20Constrained%20Optimization.pdf) |
| 2.  | [2019-JUN-24 21:32 - L5 CH5 Checking Newton-Raphson Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH5%20Checking%20Newton-Raphson%20Quiz.pdf) | 
| 3.  | [2019-JUN-24 21:32 - L5 CH4 Gradient Descent in a Sandpit.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH4%20Gradient%20Descent%20in%20a%20Sandpit.pdf) | 
| 4.  | [2019-JUN-23 21:24 - L5 CH3 Gradient Descent.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH3%20Gradient%20Descent.pdf) | 
| 5.  | [2019-JUN-23 21:24 - L5 CH2 Newton-Raphson in 1D Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH2%20Newton-Raphson%20in%201D%20Quiz.pdf) | 
| 6.  | [2019-JUN-23 21:24 - L5 CH1 Intro to Newton-Raphson.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L5%20CH1%20Intro%20to%20Newton-Raphson.pdf) | 
| 7.  | [2019-JUN-23 21:24 - L4 CH11 2D Taylor Series Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH11%202D%20Taylor%20Series%20Quiz.pdf) | 
| 8.  | [2019-JUN-22 11:03 - L4 CH10 Multivariate Taylor.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH10%20Multivariate%20Taylor.pdf) | 
| 9.  | [2019-JUN-22 11:03 - L4 CH9 Taylor Series Special Cases Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH9%20Taylor%20Series%20Special%20Cases%20Quiz.pdf) | 
| 10. | [2019-JUN-22 11:03 - L4 CH8 Linearisation.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH8%20Linearisation.pdf) | 
| 11. | [2019-JUN-22 11:03 - L4 CH7 Taylor Series Examples.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH7%20Taylor%20Series%20Examples.pdf) | 
| 12. | [2019-JUN-22 11:03 - L4 CH6 Applying The Taylor Series.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH6%20Applying%20The%20Taylor%20Series.pdf) | 
| 13. | [2019-JUN-22 11:03 - CarletonU - Robin Grosset - Fraud Detection in Class Imbalance.pdf](/assets/notes/ML/CarletonU%20-%20Robin%20Grosset%20-%20Fraud%20Detection%20in%20Class%20Imbalance.pdf) | 
| 14. | [2019-JUN-22 11:03 - CarletonU - NLP and Class Imbalance.pdf](/assets/notes/ML/CarletonU%20-%20NLP%20and%20Class%20Imbalance.pdf) | 
| 15. | [2019-JUN-22 11:03 - CarletonU - Herna Viktor.pdf](/assets/notes/ML/CarletonU%20-%20Herna%20Viktor.pdf) | 
| 16. | [2019-JUN-22 11:03 - CarletonU- Isar Nejadgholi - Privacy Preserving Data Augmentation in Medical Text Processing.pdf](/assets/notes/ML/CarletonU-%20Isar%20Nejadgholi%20-%20Privacy%20Preserving%20Data%20Augmentation%20in%20Medical%20Text%20Processing.pdf) | 
| 17. | [2019-JUN-22 11:03 - CarletonU - Benjamin Fung - Authorship and Malware Analysis.pdf](/assets/notes/ML/CarletonU%20-%20Benjamin%20Fung%20-%20Authorship%20and%20Malware%20Analysis.pdf) | 
| 18. | [2019-JUN-21 08:34 - L4 CH5 Power Series Details.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH5%20Power%20Series%20Details.pdf) | 
| 19. | [2019-JUN-21 08:34 - CarletonU What is missing from common practice in machine Learning.pdf](/assets/notes/ML/CarletonU%20-%20What%20is%20missing%20from%20common%20practice%20in%20machine%20Learning.pdf) | 
| 20. | [2019-JUN-20 09:15 - L4 CH4 Power Series Derivation.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH4%20Power%20Series%20Derivation.pdf) | 
| 21. | [2019-JUN-20 09:15 - L4 CH3 Matching Functions and Approximations Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH3%20Matching%20Functions%20and%20Approximations%20Quiz.pdf) | 
| 22. | [2019-JUN-20 09:15 - L4 CH2 Power Series.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH2%20Power%20Series.pdf) | 
| 23. | [2019-JUN-20 09:15 - L4 CH1 Building Approximate Functions.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L4%20CH1%20Building%20Approximate%20Functions.pdf) | 
| 24. | [2019-JUN-19 18:46 - L3 CH7 Backpropagation Notebook.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH7%20Backpropagation%20Notebook.pdf) | 
| 25. | [2019-JUN-18 19:19 - L3 CH6 Training Neural Networks Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH6%20Training%20Neural%20Networks%20Quiz.pdf) | 
| 26. | [2019-JUN-18 19:19 - L3 CH5 More Simple Neural Networks.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH5%20More%20Simple%20Neural%20Networks.pdf) | 
| 27. | [2019-JUN-18 19:19 - L3 CH4 Simple Artificial Neural Networks Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH4%20Simple%20Artificial%20Neural%20Networks%20Quiz.pdf) | 
| 28. | [2019-JUN-18 19:19 - L3 CH3 Simple Neural Networks.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH3%20Simple%20Neural%20Networks.pdf) | 
| 29. | [2019-JUN-18 19:19 - L3 CH2 Multivariate Chain Rule Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH2%20Multivariate%20Chain%20Rule%20Quiz.pdf) | 
| 30. | [2019-JUN-18 19:19 - L3 CH1 Introduction and Multivariate Chain Rule.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH1%20Introduction%20and%20Multivariate%20Chain%20Rule.pdf) | 
| 31. | [2019-JUN-17 09:08 - L3 CH2 Multivariate Chain Rule Quiz.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH2%20Multivariate%20Chain%20Rule%20Quiz.pdf) | 
| 32. | [2019-JUN-17 09:08 - L3 CH1 Introduction and Multivariate Chain Rule.pdf](/assets/notes/Calculus/Coursera%20-%20Mathematics%20for%20Machine%20Learning/L3%20CH1%20Introduction%20and%20Multivariate%20Chain%20Rule.pdf) | 
